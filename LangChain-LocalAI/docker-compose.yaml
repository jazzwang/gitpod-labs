version: '3.6'

services:
  api:
    image: quay.io/go-skynet/local-ai:latest
    # As initially LocalAI will download the models defined in PRELOAD_MODELS
    # you might need to tweak the healthcheck values here according to your network connection.
    # Here we give a timespan of 20m to download all the required files.
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 20
    ports:
      - 8080:8080
    environment:
      - DEBUG=true
      # https://localai.io/basics/getting_started/index.html#docker
      # Note: the binary inside the image is rebuild at the start of the container to enable CPU optimizations for the execution environment
      # you can set the environment variable REBUILD to false to prevent this behavior.
      - REBUILD=false
      - MODELS_PATH=/models
      # https://localai.io/basics/build/index.html#build-locally
      # - CMAKE_ARGS="-DLLAMA_F16C=OFF -DLLAMA_AVX512=OFF -DLLAMA_AVX2=OFF -DLLAMA_FMA=OFF"
      # You can preload different models here as well.
      # See: https://github.com/go-skynet/model-gallery
      - 'PRELOAD_MODELS=[{"url": "github:go-skynet/model-gallery/gpt4all-j.yaml", "name": "gpt-3.5-turbo"}]'
    volumes:
      - ./models:/models
    command: ["/usr/bin/local-ai" ]